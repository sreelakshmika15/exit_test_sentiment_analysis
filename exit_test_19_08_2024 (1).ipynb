{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "z2ZLsAQ-hz1_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "xM1B2BORhpfa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words =set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Mv5FqRjh08",
        "outputId": "4f131157-8dbc-4a75-bb91-8dcb551f4f21"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "data = pd.read_csv('/content/labeledTrainData.tsv',sep='\\t')"
      ],
      "metadata": {
        "id": "T_PzfaaziC59"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "NkDJ9Xx0kIC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQEjYmyUllzJ",
        "outputId": "e9db8d67-9b1b-4b42-d3a7-22c5683cf5a9"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean the review text\n",
        "def clean_review_alternate(review):\n",
        "    # Remove HTML tags\n",
        "    review_text = re.sub(r'<.*?>', ' ', review)  # Simple regex to remove HTML tags\n",
        "\n",
        "    # Remove non-letter characters and convert to lowercase\n",
        "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text).lower()\n",
        "\n",
        "    # Tokenize the text\n",
        "    words = word_tokenize(review_text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    meaningful_words = [w for w in words if not w in stop_words]\n",
        "\n",
        "    # Join the words back into one string\n",
        "    return \" \".join(meaningful_words)"
      ],
      "metadata": {
        "id": "87Vgte3Dzbah"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean all the reviews in the dataset using the alternate method\n",
        "data['cleaned_review'] = data['review'].apply(clean_review_alternate)"
      ],
      "metadata": {
        "id": "KjCh3m3Qzhsp"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few cleaned reviews to verify\n",
        "print(data[['review', 'cleaned_review']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL76Q2KGz-_d",
        "outputId": "1f86ef9b-454a-4bea-bd68-72519ee9557b"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  \\\n",
            "0  With all this stuff going down at the moment w...   \n",
            "1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
            "2  The film starts with a manager (Nicholas Bell)...   \n",
            "3  It must be assumed that those who praised this...   \n",
            "4  Superbly trashy and wondrously unpretentious 8...   \n",
            "\n",
            "                                      cleaned_review  \n",
            "0  stuff going moment mj started listening music ...  \n",
            "1  classic war worlds timothy hines entertaining ...  \n",
            "2  film starts manager nicholas bell giving welco...  \n",
            "3  must assumed praised film greatest filmed oper...  \n",
            "4  superbly trashy wondrously unpretentious explo...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction using TF-IDF"
      ],
      "metadata": {
        "id": "EY4Un9oLmaj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Bn5zXzO1moH5"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words = 'english')\n",
        "#fit and transform the cleaned review\n",
        "x = tfidf_vectorizer.fit_transform(data['cleaned_review']).toarray()\n",
        "y = data['sentiment']\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 42)"
      ],
      "metadata": {
        "id": "KK_4JaZzlhPR"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building and Evaluation using Logistic regression"
      ],
      "metadata": {
        "id": "KeB6oMiItNPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "9EpVr-RDtsdI"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "SN6_H-I1tVZV",
        "outputId": "0a1b4936-1aa9-4710-eb48-e59c9cfddace"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model prediction\n",
        "y_pred_lr = model.predict(x_test)\n"
      ],
      "metadata": {
        "id": "iditfrAntrL1"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqX8RveA09K-",
        "outputId": "9ead51e0-b76e-4e2b-c9b2-40a0ef2787ba"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.8808\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      2481\n",
            "           1       0.87      0.89      0.88      2519\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.88      0.88      0.88      5000\n",
            "weighted avg       0.88      0.88      0.88      5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network"
      ],
      "metadata": {
        "id": "mbkgkwtR1Vic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "u18MfB2A1MVx"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the neural network model\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(128,input_dim = x_train.shape[1],activation = 'relu'))\n",
        "model1.add(Dense(1,activation = 'sigmoid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBzGtu6_1gxG",
        "outputId": "accbabb8-1ff2-4887-d712-00d224ed2035"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "model1.compile(optimizer = 'adam',loss='binary_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Huc1s9u_2F0I"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "model1.fit(x_train,y_train,epochs = 5,batch_size = 512, validation_data = (x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iofOjKbL2iI7",
        "outputId": "2fc86a95-e0b7-4187-8cb1-73e100c090df"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.7286 - loss: 0.6540 - val_accuracy: 0.8524 - val_loss: 0.4951\n",
            "Epoch 2/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8705 - loss: 0.4424 - val_accuracy: 0.8684 - val_loss: 0.3627\n",
            "Epoch 3/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8934 - loss: 0.3173 - val_accuracy: 0.8766 - val_loss: 0.3091\n",
            "Epoch 4/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9098 - loss: 0.2588 - val_accuracy: 0.8792 - val_loss: 0.2878\n",
            "Epoch 5/5\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9192 - loss: 0.2310 - val_accuracy: 0.8800 - val_loss: 0.2805\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79651334a6b0>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model\n",
        "NN_loss,NN_accuracy = model1.evaluate(x_test,y_test)\n",
        "print('Neural Network Accuracy',NN_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDuKQicF28yh",
        "outputId": "b9912677-c9cb-4db9-c2d0-546d91dfb462"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8789 - loss: 0.2777\n",
            "Neural Network Accuracy 0.8799999952316284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both the Logistic regression model and Neural network model performed well on the sentimental analysis.Logistic regression slightly well performed than neural network,making it a strong choice for this specific dataset"
      ],
      "metadata": {
        "id": "0oPjFJHS-5i6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyHUdvz4GQib"
      },
      "execution_count": 120,
      "outputs": []
    }
  ]
}